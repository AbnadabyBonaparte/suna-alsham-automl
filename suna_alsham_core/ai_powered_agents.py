#!/usr/bin/env python3
"""
MÃ³dulo dos Agentes com IA (AI-Powered) - SUNA-ALSHAM

[VersÃ£o Defensiva] - Adiciona validaÃ§Ã£o de robustez na entrada para
recusar requisiÃ§Ãµes malformadas imediatamente, evitando loops de fallback.
"""

import asyncio
import logging
import os
import json
from typing import Any, Dict, List

# --- Importa as bibliotecas dos trÃªs provedores de IA ---
try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    from anthropic import AsyncAnthropic
    CLAUDE_AVAILABLE = True
except ImportError:
    CLAUDE_AVAILABLE = False

from suna_alsham_core.multi_agent_network import (
    AgentMessage,
    AgentType,
    BaseNetworkAgent,
    MessageType,
    Priority,
)

logger = logging.getLogger(__name__)

class AIAnalyzerAgent(BaseNetworkAgent):
    """
    Agente especialista que atua como um roteador de IA inteligente,
    selecionando o melhor LLM para a tarefa e usando um sistema de fallback.
    """
    def __init__(self, agent_id: str, message_bus):
        """Inicializa o AIAnalyzerAgent com mÃºltiplos clientes de IA."""
        super().__init__(agent_id, AgentType.AI_POWERED, message_bus)
        self.capabilities.extend(["intelligent_llm_routing", "multi_llm_fallback"])
        
        self.openai_client, self.gemini_model, self.claude_client = None, None, None

        # Configura OpenAI (GPT)
        if OPENAI_AVAILABLE and os.environ.get("OPENAI_API_KEY"):
            self.openai_client = AsyncOpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
            logger.info("CÃ©rebro 1 (OpenAI/GPT) configurado e online.")
        
        # Configura Google (Gemini)
        if GEMINI_AVAILABLE and os.environ.get("GEMINI_API_KEY"):
            genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
            self.gemini_model = genai.GenerativeModel('gemini-pro')
            logger.info("CÃ©rebro 2 (Google/Gemini) configurado e online.")

        # Configura Anthropic (Claude)
        if CLAUDE_AVAILABLE and os.environ.get("CLAUDE_API_KEY"):
            self.claude_client = AsyncAnthropic(api_key=os.environ.get("CLAUDE_API_KEY"))
            logger.info("CÃ©rebro 3 (Anthropic/Claude) configurado e online.")

        if not any([self.openai_client, self.gemini_model, self.claude_client]):
            self.status = "degraded"
            logger.critical("Nenhum cÃ©rebro de IA disponÃ­vel. O AIAnalyzerAgent estÃ¡ offline.")
        
        logger.info(f"ğŸ§  {self.agent_id} (Analisador CÃ©rebro Triplo) evoluÃ­do e inicializado.")

    def _select_best_provider_order(self, request_content: Dict) -> List[str]:
        # ... (cÃ³digo existente) ...
        pass

    async def _internal_handle_message(self, message: AgentMessage):
        """Processa a requisiÃ§Ã£o usando o roteamento inteligente e o sistema de fallback."""
        
        # --- VALIDAÃ‡ÃƒO DEFENSIVA ADICIONADA AQUI ---
        req_type = message.content.get("request_type")
        prompt = message.content.get("text")
        if not req_type:
            await self.publish_error_response(
                message,
                "Tipo de requisiÃ§Ã£o ('request_type') ausente ou nulo ao acionar o AIAnalyzerAgent."
            )
            return
        if not prompt:
            await self.publish_error_response(
                message,
                "Campo 'text' ausente ou vazio ao acionar o AIAnalyzerAgent."
            )
            return
        # --- FIM DA VALIDAÃ‡ÃƒO ---

        if self.status == "degraded":
            await self.publish_error_response(message, "ServiÃ§o de IA indisponÃ­vel.")
            return

        provider_order = self._select_best_provider_order(message.content)
        
        last_error = None
        for i, provider in enumerate(provider_order):
            logger.info(f"Tentativa {i+1}/{len(provider_order)}: Usando o cÃ©rebro '{provider}'...")
            success = False
            result = {}
            
            try:
                if provider == 'openai' and self.openai_client:
                    result = await self._call_openai(message.content)
                    success = True
                elif provider == 'gemini' and self.gemini_model:
                    result = await self._call_gemini(message.content)
                    success = True
                elif provider == 'claude' and self.claude_client:
                    result = await self._call_claude(message.content)
                    success = True

                if success:
                    response_content = {"status": "completed", "result": result, "source": provider.capitalize()}
                    await self.publish_response(message, response_content)
                    return # MissÃ£o cumprida!

            except Exception as e:
                last_error = e
                logger.error(f"âŒ Erro no cÃ©rebro '{provider}': {e}. Tentando o prÃ³ximo cÃ©rebro...")
        
        logger.critical(f"Falha em todos os provedores de IA. Ãšltimo erro: {last_error}")
        await self.publish_error_response(message, f"Falha em todos os provedores de IA disponÃ­veis. Ãšltimo erro: {last_error}")

    # ... (resto do cÃ³digo, como _call_openai, _call_gemini, etc., permanece o mesmo) ...

def create_ai_agents(message_bus) -> List[BaseNetworkAgent]:
    # ... (cÃ³digo existente) ...
    pass
