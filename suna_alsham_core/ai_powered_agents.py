#!/usr/bin/env python3
"""
MÃ³dulo dos Agentes com IA (AI-Powered) â€“ SUNA-ALSHAM

VersÃ£o Viva â€“ Tradutor Universal. Entende qualquer texto e converte em JSON de missÃ£o.
"""

import asyncio
import json
import logging
import os
from typing import Dict, List

try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from suna_alsham_core.multi_agent_network import (
    AgentMessage,
    AgentType,
    BaseNetworkAgent,
    MessageType,
)

logger = logging.getLogger(__name__)

class AIAnalyzerAgent(BaseNetworkAgent):
    """
    Tradutor Universal â€“ Transforma texto em planos estruturados.
    Usa exclusivamente OpenAI.
    """
    def __init__(self, agent_id: str, message_bus):
        super().__init__(agent_id, AgentType.AI_POWERED, message_bus)
        self.capabilities.extend(["intent_extraction", "universal_translation"])

        if OPENAI_AVAILABLE and os.environ.get("OPENAI_API_KEY"):
            self.openai_client = AsyncOpenAI(api_key=os.environ["OPENAI_API_KEY"])
            logger.info("CÃ©rebro (OpenAI) configurado e online.")
        else:
            self.openai_client = None
            self.status = "degraded"
            logger.critical("OpenAI nÃ£o disponÃ­vel. AIAnalyzerAgent em modo degradado.")

        logger.info(f"ğŸ§  {self.agent_id} (Tradutor Universal) inicializado.")

    async def _internal_handle_message(self, message: AgentMessage):
        if message.message_type != MessageType.REQUEST:
            return

        req_type = message.content.get("request_type")
        prompt = message.content.get("text") or json.dumps(message.content)
        if not prompt:
            await self.publish_error_response(message, "RequisiÃ§Ã£o sem conteÃºdo vÃ¡lido.")
            return

        if self.status == "degraded":
            await self.publish_error_response(message, "ServiÃ§o de IA indisponÃ­vel.")
            return

        try:
            result = await self._call_openai(req_type, prompt)
            await self.publish_response(message, {
                "status": "completed",
                "result": result,
                "source": "OpenAI"
            })
        except Exception as e:
            logger.error(f"âŒ Erro OpenAI: {e}")
            await self.publish_error_response(message, f"Falha no OpenAI: {e}")

    async def _call_openai(self, req_type: str, prompt: str) -> Dict:
        """
        Se for um pedido de missÃ£o, converte texto para JSON de missÃ£o.
        Caso contrÃ¡rio, responde texto livre.
        """
        model_to_use = "gpt-4.1-mini"

        chat_completion = await self.openai_client.chat.completions.create(
            model=model_to_use,
            messages=[{"role": "user", "content": prompt}]
        )
        result_text = chat_completion.choices[0].message.content

        # ğŸ”¥ Se a requisiÃ§Ã£o for de geraÃ§Ã£o estruturada, tenta extrair JSON
        if "generate_structured_text" in (req_type or "") or "execute_complex_task" in (req_type or ""):
            try:
                return {"structured_data": json.loads(result_text)}
            except json.JSONDecodeError:
                # Tenta limpar o JSON
                json_str = result_text[result_text.find("{"):result_text.rfind("}") + 1]
                try:
                    return {"structured_data": json.loads(json_str)}
                except json.JSONDecodeError:
                    # Se nÃ£o for JSON, devolve texto puro
                    return {"text": result_text}

        return {"text": result_text}

def create_ai_agents(message_bus) -> List[BaseNetworkAgent]:
    agents: List[BaseNetworkAgent] = []
    logger.info("ğŸ¤– Criando AIAnalyzerAgent (Tradutor Universal)...")
    try:
        agent = AIAnalyzerAgent("ai_analyzer_001", message_bus)
        agents.append(agent)
    except Exception as e:
        logger.error(f"âŒ Erro criando AIAnalyzerAgent: {e}", exc_info=True)
    return agents
