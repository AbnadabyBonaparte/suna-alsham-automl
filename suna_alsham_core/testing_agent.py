#!/usr/bin/env python3
"""
MÃ³dulo do Testing Agent - SUNA-ALSHAM

Define o agente de testes automatizados avanÃ§ado, responsÃ¡vel por executar
testes, monitorar cobertura de cÃ³digo e detectar regressÃµes no sistema.
"""

import asyncio
import json
import logging
import os
import subprocess
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional

# Import corrigido, apontando para o mÃ³dulo central da rede
from suna_alsham_core.multi_agent_network import (
    AgentMessage,
    AgentType,
    BaseNetworkAgent,
    Priority,
)

logger = logging.getLogger(__name__)


# --- Enums e Dataclasses para Tipagem Forte ---

class TestType(Enum):
    """Tipos de testes que o agente pode executar."""
    UNIT = "unit"
    INTEGRATION = "integration"
    PERFORMANCE = "performance"
    REGRESSION = "regression"


class TestStatus(Enum):
    """Status de uma execuÃ§Ã£o de teste."""
    PENDING = "pending"
    RUNNING = "running"
    PASSED = "passed"
    FAILED = "failed"
    ERROR = "error"


@dataclass
class TestRun:
    """Representa uma execuÃ§Ã£o completa de uma suÃ­te de testes."""
    run_id: str
    test_type: TestType
    status: TestStatus = TestStatus.PENDING
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    summary: Dict[str, int] = field(default_factory=dict)
    coverage_percentage: float = 0.0
    report_path: Optional[str] = None


# --- Classe Principal do Agente ---

class TestingAgent(BaseNetworkAgent):
    """
    Agente especializado em testes automatizados e validaÃ§Ã£o de qualidade.
    Orquestra a execuÃ§Ã£o de testes, mede cobertura e detecta regressÃµes.
    """

    def __init__(self, agent_id: str, message_bus):
        """Inicializa o TestingAgent."""
        super().__init__(agent_id, AgentType.SPECIALIZED, message_bus)
        self.capabilities.extend([
            "automated_testing",
            "code_coverage",
            "regression_testing",
            "test_generation",
            "quality_assurance",
        ])
        
        # ConfiguraÃ§Ãµes do ambiente de teste
        self.test_directory = Path("./tests")
        self.reports_directory = self.test_directory / "reports"
        self.test_directory.mkdir(exist_ok=True)
        self.reports_directory.mkdir(exist_ok=True)

        self.test_queue = asyncio.Queue()
        self.active_test_runs: Dict[str, TestRun] = {}
        
        self._testing_task = None
        logger.info(f"ğŸ§ª {self.agent_id} (Agente de Testes) inicializado.")

    async def start_testing_service(self):
        """Inicia os serviÃ§os de background do agente."""
        if not self._testing_task:
            self._testing_task = asyncio.create_task(self._testing_loop())
            logger.info(f"ğŸ§ª {self.agent_id} iniciou serviÃ§o de testes.")

    async def _testing_loop(self):
        """Loop principal que processa a fila de execuÃ§Ãµes de teste."""
        while True:
            try:
                test_request = await self.test_queue.get()
                await self._process_test_request(test_request)
            except asyncio.CancelledError:
                logger.info(f"Loop de testes do {self.agent_id} cancelado.")
                break
            except Exception as e:
                logger.error(f"âŒ Erro no loop de testes: {e}", exc_info=True)

    async def handle_message(self, message: AgentMessage):
        """Processa requisiÃ§Ãµes para execuÃ§Ã£o de testes."""
        await super().handle_message(message)
        if message.message_type == MessageType.REQUEST:
            request_type = message.content.get("request_type")
            if request_type == "run_tests":
                result = await self.run_tests(message.content)
                await self.message_bus.publish(self.create_response(message, result))
            else:
                logger.warning(f"AÃ§Ã£o de teste desconhecida: {request_type}")

    async def run_tests(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Cria e enfileira um novo trabalho de execuÃ§Ã£o de testes.
        """
        try:
            test_type = TestType(request_data.get("type", "unit"))
            pattern = request_data.get("pattern", "test_*.py")
            
            run_id = f"test_run_{int(time.time())}"
            test_run = TestRun(run_id=run_id, test_type=test_type)
            
            await self.test_queue.put({"run": test_run, "pattern": pattern})
            
            logger.info(f"ğŸ“¥ Novo job de teste enfileirado: {run_id} ({test_type.value})")
            return {"status": "queued", "run_id": run_id}
        except Exception as e:
            logger.error(f"âŒ Erro ao criar job de teste: {e}", exc_info=True)
            return {"status": "error", "message": str(e)}

    async def _process_test_request(self, request: Dict[str, Any]):
        """Processa uma requisiÃ§Ã£o da fila de testes."""
        run: TestRun = request["pattern"]
        pattern: str = request["pattern"]
        
        self.active_test_runs[run.run_id] = run
        run.status = TestStatus.RUNNING
        run.start_time = datetime.now()

        try:
            # Comando para executar pytest com cobertura e relatÃ³rio JSON
            report_path = self.reports_directory / f"{run.run_id}.json"
            cmd = [
                sys.executable, "-m", "pytest",
                "--cov=suna_alsham_core", # Medir cobertura do nosso nÃºcleo
                f"--cov-report=json:{report_path}",
                "-q", # Modo quieto para saÃ­da limpa
                self.test_directory.as_posix() # DiretÃ³rio de testes
            ]
            
            proc = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )
            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=300)

            if proc.returncode == 0:
                run.status = TestStatus.PASSED
            else:
                run.status = TestStatus.FAILED
            
            # Processar o relatÃ³rio de cobertura
            if report_path.exists():
                with open(report_path) as f:
                    coverage_data = json.load(f)
                run.coverage_percentage = coverage_data.get("totals", {}).get("percent_covered", 0)
                run.report_path = str(report_path)
        
        except asyncio.TimeoutError:
            run.status = TestStatus.TIMEOUT
            logger.error(f"âŒ Teste {run.run_id} excedeu o tempo limite.")
        except Exception as e:
            run.status = TestStatus.ERROR
            logger.error(f"âŒ Erro executando testes para {run.run_id}: {e}", exc_info=True)

        finally:
            run.end_time = datetime.now()
            if run.run_id in self.active_test_runs:
                del self.active_test_runs[run.run_id]


def create_testing_agent(message_bus) -> List[BaseNetworkAgent]:
    """Cria o agente de Testes Automatizados."""
    agents = []
    logger.info("ğŸ§ª Criando TestingAgent...")
    try:
        agent = TestingAgent("testing_001", message_bus)
        asyncio.create_task(agent.start_testing_service())
        agents.append(agent)
    except Exception as e:
        logger.error(f"âŒ Erro crÃ­tico criando TestingAgent: {e}", exc_info=True)
    return agents
