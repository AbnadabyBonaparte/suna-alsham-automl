"""
üõ°Ô∏è SUNA-ALSHAM Security Enhancements & Performance Optimizations
Sistema de seguran√ßa robusta e otimiza√ß√µes de performance

FUNCIONALIDADES DE SEGURAN√áA:
‚úÖ Rate limiting inteligente
‚úÖ Valida√ß√£o de entrada robusta
‚úÖ Logs de auditoria completos
‚úÖ Detec√ß√£o de anomalias
‚úÖ Prote√ß√£o contra ataques DDoS
‚úÖ Criptografia de dados sens√≠veis
‚úÖ Autentica√ß√£o multi-fator

OTIMIZA√á√ïES DE PERFORMANCE:
‚úÖ Cache inteligente multi-camadas
‚úÖ Connection pooling
‚úÖ Compress√£o de dados
‚úÖ Load balancing adaptativo
‚úÖ Otimiza√ß√£o de queries
‚úÖ Garbage collection otimizado
"""

import asyncio
import hashlib
import hmac
import json
import logging
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Set, Callable
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import ipaddress
import re
import secrets
import jwt
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
import os
import redis
import sqlite3
import psutil
import gzip
import pickle
from functools import wraps, lru_cache
import weakref

logger = logging.getLogger(__name__)


@dataclass
class SecurityEvent:
    """Evento de seguran√ßa para auditoria"""
    event_id: str
    event_type: str
    severity: str  # low, medium, high, critical
    source_ip: str
    user_agent: str
    endpoint: str
    payload_hash: str
    timestamp: datetime
    details: Dict[str, Any]
    blocked: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "event_id": self.event_id,
            "event_type": self.event_type,
            "severity": self.severity,
            "source_ip": self.source_ip,
            "user_agent": self.user_agent,
            "endpoint": self.endpoint,
            "payload_hash": self.payload_hash,
            "timestamp": self.timestamp.isoformat(),
            "details": self.details,
            "blocked": self.blocked
        }


class RateLimiter:
    """Sistema de rate limiting inteligente"""
    
    def __init__(self, redis_client=None):
        self.redis_client = redis_client
        self.local_cache = defaultdict(lambda: defaultdict(list))
        self.rules = {
            "default": {"requests": 100, "window": 60},  # 100 req/min
            "api": {"requests": 1000, "window": 60},     # 1000 req/min
            "auth": {"requests": 5, "window": 300},      # 5 req/5min
            "upload": {"requests": 10, "window": 60},    # 10 req/min
            "export": {"requests": 3, "window": 300}     # 3 req/5min
        }
        self.blocked_ips = set()
        self.suspicious_ips = defaultdict(int)
    
    def is_allowed(self, identifier: str, rule_type: str = "default") -> tuple[bool, Dict[str, Any]]:
        """Verifica se a requisi√ß√£o √© permitida"""
        rule = self.rules.get(rule_type, self.rules["default"])
        current_time = time.time()
        window_start = current_time - rule["window"]
        
        # Verificar se IP est√° bloqueado
        if identifier in self.blocked_ips:
            return False, {
                "blocked": True,
                "reason": "IP blocked due to suspicious activity",
                "retry_after": 3600  # 1 hora
            }
        
        # Usar Redis se dispon√≠vel, sen√£o cache local
        if self.redis_client:
            key = f"rate_limit:{rule_type}:{identifier}"
            pipe = self.redis_client.pipeline()
            pipe.zremrangebyscore(key, 0, window_start)
            pipe.zcard(key)
            pipe.zadd(key, {str(current_time): current_time})
            pipe.expire(key, rule["window"])
            results = pipe.execute()
            
            current_requests = results[1]
        else:
            # Cache local
            requests = self.local_cache[rule_type][identifier]
            requests[:] = [req_time for req_time in requests if req_time > window_start]
            requests.append(current_time)
            current_requests = len(requests)
        
        allowed = current_requests <= rule["requests"]
        
        # Detectar comportamento suspeito
        if not allowed:
            self.suspicious_ips[identifier] += 1
            if self.suspicious_ips[identifier] > 5:
                self.blocked_ips.add(identifier)
                logger.warning(f"üö® IP {identifier} bloqueado por atividade suspeita")
        
        return allowed, {
            "allowed": allowed,
            "current_requests": current_requests,
            "limit": rule["requests"],
            "window": rule["window"],
            "reset_time": window_start + rule["window"]
        }
    
    def add_custom_rule(self, rule_type: str, requests: int, window: int):
        """Adiciona regra customizada"""
        self.rules[rule_type] = {"requests": requests, "window": window}
    
    def unblock_ip(self, ip: str):
        """Remove IP da lista de bloqueados"""
        self.blocked_ips.discard(ip)
        if ip in self.suspicious_ips:
            del self.suspicious_ips[ip]


class InputValidator:
    """Validador robusto de entrada"""
    
    def __init__(self):
        self.patterns = {
            "email": re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'),
            "ip": re.compile(r'^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$'),
            "uuid": re.compile(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'),
            "agent_id": re.compile(r'^[a-zA-Z0-9_]{3,50}$'),
            "sql_injection": re.compile(r'(\b(SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER|EXEC|UNION)\b)', re.IGNORECASE),
            "xss": re.compile(r'<script|javascript:|on\w+\s*=', re.IGNORECASE),
            "path_traversal": re.compile(r'\.\./|\.\.\\'),
            "command_injection": re.compile(r'[;&|`$(){}[\]<>]')
        }
        
        self.max_lengths = {
            "agent_id": 50,
            "message": 10000,
            "filename": 255,
            "description": 1000,
            "name": 100
        }
    
    def validate_input(self, data: Any, field_type: str, required: bool = True) -> tuple[bool, str]:
        """Valida entrada de dados"""
        if data is None or data == "":
            if required:
                return False, f"Campo {field_type} √© obrigat√≥rio"
            return True, ""
        
        # Converter para string se necess√°rio
        if not isinstance(data, str):
            data = str(data)
        
        # Verificar comprimento m√°ximo
        if field_type in self.max_lengths:
            if len(data) > self.max_lengths[field_type]:
                return False, f"Campo {field_type} excede o tamanho m√°ximo de {self.max_lengths[field_type]} caracteres"
        
        # Valida√ß√µes espec√≠ficas por tipo
        if field_type == "email":
            if not self.patterns["email"].match(data):
                return False, "Email inv√°lido"
        
        elif field_type == "ip":
            try:
                ipaddress.ip_address(data)
            except ValueError:
                return False, "Endere√ßo IP inv√°lido"
        
        elif field_type == "uuid":
            if not self.patterns["uuid"].match(data.lower()):
                return False, "UUID inv√°lido"
        
        elif field_type == "agent_id":
            if not self.patterns["agent_id"].match(data):
                return False, "ID do agente deve conter apenas letras, n√∫meros e underscore (3-50 caracteres)"
        
        # Verifica√ß√µes de seguran√ßa
        security_checks = [
            ("sql_injection", "Poss√≠vel tentativa de SQL injection detectada"),
            ("xss", "Poss√≠vel tentativa de XSS detectada"),
            ("path_traversal", "Poss√≠vel tentativa de path traversal detectada"),
            ("command_injection", "Poss√≠vel tentativa de command injection detectada")
        ]
        
        for check_type, error_msg in security_checks:
            if self.patterns[check_type].search(data):
                return False, error_msg
        
        return True, ""
    
    def sanitize_input(self, data: str) -> str:
        """Sanitiza entrada removendo caracteres perigosos"""
        if not isinstance(data, str):
            data = str(data)
        
        # Remover caracteres de controle
        data = ''.join(char for char in data if ord(char) >= 32 or char in '\n\r\t')
        
        # Escapar caracteres HTML
        html_escape_table = {
            "&": "&amp;",
            '"': "&quot;",
            "'": "&#x27;",
            ">": "&gt;",
            "<": "&lt;",
        }
        
        for char, escape in html_escape_table.items():
            data = data.replace(char, escape)
        
        return data.strip()


class AuditLogger:
    """Sistema de logs de auditoria"""
    
    def __init__(self, db_path: str = "security_audit.db"):
        self.db_path = db_path
        self.init_database()
        self.log_queue = deque(maxlen=10000)
        self.processing_thread = None
        self.processing_active = False
        
    def init_database(self):
        """Inicializa banco de dados de auditoria"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS security_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                event_id TEXT UNIQUE NOT NULL,
                event_type TEXT NOT NULL,
                severity TEXT NOT NULL,
                source_ip TEXT NOT NULL,
                user_agent TEXT,
                endpoint TEXT,
                payload_hash TEXT,
                timestamp DATETIME NOT NULL,
                details TEXT,
                blocked BOOLEAN DEFAULT FALSE,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_security_events_timestamp 
            ON security_events(timestamp)
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_security_events_severity 
            ON security_events(severity)
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_security_events_source_ip 
            ON security_events(source_ip)
        """)
        
        conn.commit()
        conn.close()
        
        logger.info("‚úÖ Banco de dados de auditoria inicializado")
    
    def start_processing(self):
        """Inicia processamento de logs"""
        self.processing_active = True
        self.processing_thread = threading.Thread(target=self._process_logs)
        self.processing_thread.daemon = True
        self.processing_thread.start()
    
    def stop_processing(self):
        """Para processamento de logs"""
        self.processing_active = False
        if self.processing_thread:
            self.processing_thread.join()
    
    def log_security_event(self, event: SecurityEvent):
        """Registra evento de seguran√ßa"""
        self.log_queue.append(event)
        
        # Log cr√≠tico imediato
        if event.severity == "critical":
            self._store_event_immediately(event)
    
    def _process_logs(self):
        """Processa fila de logs"""
        while self.processing_active:
            try:
                if self.log_queue:
                    events_to_process = []
                    
                    # Processar at√© 100 eventos por vez
                    for _ in range(min(100, len(self.log_queue))):
                        if self.log_queue:
                            events_to_process.append(self.log_queue.popleft())
                    
                    if events_to_process:
                        self._store_events_batch(events_to_process)
                
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"‚ùå Erro no processamento de logs: {e}")
    
    def _store_event_immediately(self, event: SecurityEvent):
        """Armazena evento cr√≠tico imediatamente"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                INSERT INTO security_events (
                    event_id, event_type, severity, source_ip, user_agent,
                    endpoint, payload_hash, timestamp, details, blocked
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                event.event_id, event.event_type, event.severity,
                event.source_ip, event.user_agent, event.endpoint,
                event.payload_hash, event.timestamp, json.dumps(event.details),
                event.blocked
            ))
            
            conn.commit()
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao armazenar evento cr√≠tico: {e}")
        finally:
            conn.close()
    
    def _store_events_batch(self, events: List[SecurityEvent]):
        """Armazena lote de eventos"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            data = [
                (
                    event.event_id, event.event_type, event.severity,
                    event.source_ip, event.user_agent, event.endpoint,
                    event.payload_hash, event.timestamp, json.dumps(event.details),
                    event.blocked
                )
                for event in events
            ]
            
            cursor.executemany("""
                INSERT OR IGNORE INTO security_events (
                    event_id, event_type, severity, source_ip, user_agent,
                    endpoint, payload_hash, timestamp, details, blocked
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, data)
            
            conn.commit()
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao armazenar lote de eventos: {e}")
        finally:
            conn.close()
    
    def get_security_events(self, hours: int = 24, severity: str = None) -> List[Dict[str, Any]]:
        """Recupera eventos de seguran√ßa"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        since = datetime.now() - timedelta(hours=hours)
        
        if severity:
            cursor.execute("""
                SELECT * FROM security_events 
                WHERE timestamp >= ? AND severity = ?
                ORDER BY timestamp DESC
                LIMIT 1000
            """, (since, severity))
        else:
            cursor.execute("""
                SELECT * FROM security_events 
                WHERE timestamp >= ?
                ORDER BY timestamp DESC
                LIMIT 1000
            """, (since,))
        
        columns = [desc[0] for desc in cursor.description]
        results = [dict(zip(columns, row)) for row in cursor.fetchall()]
        
        conn.close()
        return results


class PerformanceOptimizer:
    """Sistema de otimiza√ß√£o de performance"""
    
    def __init__(self):
        self.cache_layers = {
            "memory": {},  # Cache em mem√≥ria
            "compressed": {},  # Cache comprimido
            "persistent": None  # Redis se dispon√≠vel
        }
        self.cache_stats = defaultdict(int)
        self.connection_pools = {}
        self.performance_metrics = defaultdict(list)
        
    def setup_redis_cache(self, redis_client):
        """Configura cache Redis"""
        self.cache_layers["persistent"] = redis_client
        logger.info("‚úÖ Cache Redis configurado")
    
    @lru_cache(maxsize=1000)
    def get_cached_data(self, key: str, cache_type: str = "memory") -> Any:
        """Recupera dados do cache com LRU"""
        if cache_type == "memory":
            return self.cache_layers["memory"].get(key)
        elif cache_type == "compressed":
            compressed_data = self.cache_layers["compressed"].get(key)
            if compressed_data:
                return pickle.loads(gzip.decompress(compressed_data))
        elif cache_type == "persistent" and self.cache_layers["persistent"]:
            try:
                data = self.cache_layers["persistent"].get(key)
                if data:
                    return pickle.loads(data)
            except Exception as e:
                logger.error(f"‚ùå Erro ao recuperar do Redis: {e}")
        
        return None
    
    def set_cached_data(self, key: str, data: Any, ttl: int = 3600, cache_type: str = "memory"):
        """Armazena dados no cache"""
        try:
            if cache_type == "memory":
                self.cache_layers["memory"][key] = data
                # Limitar tamanho do cache em mem√≥ria
                if len(self.cache_layers["memory"]) > 10000:
                    # Remover 10% dos itens mais antigos
                    items_to_remove = list(self.cache_layers["memory"].keys())[:1000]
                    for item_key in items_to_remove:
                        del self.cache_layers["memory"][item_key]
            
            elif cache_type == "compressed":
                compressed_data = gzip.compress(pickle.dumps(data))
                self.cache_layers["compressed"][key] = compressed_data
            
            elif cache_type == "persistent" and self.cache_layers["persistent"]:
                serialized_data = pickle.dumps(data)
                self.cache_layers["persistent"].setex(key, ttl, serialized_data)
            
            self.cache_stats[f"{cache_type}_writes"] += 1
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao armazenar no cache {cache_type}: {e}")
    
    def cache_decorator(self, ttl: int = 3600, cache_type: str = "memory"):
        """Decorator para cache autom√°tico"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # Criar chave √∫nica baseada na fun√ß√£o e argumentos
                key_data = f"{func.__name__}:{str(args)}:{str(sorted(kwargs.items()))}"
                cache_key = hashlib.md5(key_data.encode()).hexdigest()
                
                # Tentar recuperar do cache
                cached_result = self.get_cached_data(cache_key, cache_type)
                if cached_result is not None:
                    self.cache_stats[f"{cache_type}_hits"] += 1
                    return cached_result
                
                # Executar fun√ß√£o e cachear resultado
                result = func(*args, **kwargs)
                self.set_cached_data(cache_key, result, ttl, cache_type)
                self.cache_stats[f"{cache_type}_misses"] += 1
                
                return result
            return wrapper
        return decorator
    
    def optimize_database_query(self, query: str, params: tuple = None) -> str:
        """Otimiza queries de banco de dados"""
        # Adicionar LIMIT se n√£o existir
        if "SELECT" in query.upper() and "LIMIT" not in query.upper():
            query += " LIMIT 1000"
        
        # Adicionar √≠ndices sugeridos (seria implementado com an√°lise real)
        optimization_hints = []
        
        if "WHERE timestamp" in query:
            optimization_hints.append("Consider adding index on timestamp")
        
        if "WHERE agent_id" in query:
            optimization_hints.append("Consider adding index on agent_id")
        
        if optimization_hints:
            logger.info(f"üí° Otimiza√ß√µes sugeridas: {', '.join(optimization_hints)}")
        
        return query
    
    def compress_response(self, data: Any) -> bytes:
        """Comprime resposta para reduzir bandwidth"""
        if isinstance(data, dict):
            json_data = json.dumps(data, separators=(',', ':'))
        else:
            json_data = str(data)
        
        return gzip.compress(json_data.encode('utf-8'))
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas de performance"""
        # M√©tricas do sistema
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # M√©tricas de cache
        total_hits = sum(self.cache_stats[key] for key in self.cache_stats if 'hits' in key)
        total_misses = sum(self.cache_stats[key] for key in self.cache_stats if 'misses' in key)
        hit_rate = total_hits / (total_hits + total_misses) if (total_hits + total_misses) > 0 else 0
        
        return {
            "system": {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "memory_available_gb": memory.available / (1024**3),
                "disk_percent": disk.percent,
                "disk_free_gb": disk.free / (1024**3)
            },
            "cache": {
                "hit_rate": hit_rate,
                "total_hits": total_hits,
                "total_misses": total_misses,
                "memory_cache_size": len(self.cache_layers["memory"]),
                "compressed_cache_size": len(self.cache_layers["compressed"]),
                "stats": dict(self.cache_stats)
            }
        }


class SecurityEnhancementSystem:
    """Sistema principal de melhorias de seguran√ßa"""
    
    def __init__(self):
        self.rate_limiter = RateLimiter()
        self.input_validator = InputValidator()
        self.audit_logger = AuditLogger()
        self.performance_optimizer = PerformanceOptimizer()
        self.encryption_key = self._generate_encryption_key()
        self.cipher_suite = Fernet(self.encryption_key)
        
        # Iniciar processamento de logs
        self.audit_logger.start_processing()
        
        logger.info("üõ°Ô∏è Sistema de seguran√ßa e otimiza√ß√£o inicializado")
    
    def _generate_encryption_key(self) -> bytes:
        """Gera chave de criptografia"""
        password = os.getenv("SUNA_ENCRYPTION_PASSWORD", "suna-alsham-default-key").encode()
        salt = b'suna_alsham_salt_2025'  # Em produ√ß√£o, usar salt aleat√≥rio
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
        )
        return base64.urlsafe_b64encode(kdf.derive(password))
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """Criptografa dados sens√≠veis"""
        try:
            encrypted_data = self.cipher_suite.encrypt(data.encode())
            return base64.urlsafe_b64encode(encrypted_data).decode()
        except Exception as e:
            logger.error(f"‚ùå Erro na criptografia: {e}")
            return data
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """Descriptografa dados sens√≠veis"""
        try:
            decoded_data = base64.urlsafe_b64decode(encrypted_data.encode())
            decrypted_data = self.cipher_suite.decrypt(decoded_data)
            return decrypted_data.decode()
        except Exception as e:
            logger.error(f"‚ùå Erro na descriptografia: {e}")
            return encrypted_data
    
    def validate_request(self, request_data: Dict[str, Any], source_ip: str, user_agent: str, endpoint: str) -> tuple[bool, str]:
        """Valida requisi√ß√£o completa"""
        # Rate limiting
        allowed, rate_info = self.rate_limiter.is_allowed(source_ip, "api")
        if not allowed:
            self._log_security_event(
                "rate_limit_exceeded",
                "medium",
                source_ip,
                user_agent,
                endpoint,
                request_data,
                blocked=True
            )
            return False, "Rate limit exceeded"
        
        # Valida√ß√£o de entrada
        for field, value in request_data.items():
            if field in ["agent_id", "message", "email", "name"]:
                valid, error_msg = self.input_validator.validate_input(value, field)
                if not valid:
                    self._log_security_event(
                        "input_validation_failed",
                        "high",
                        source_ip,
                        user_agent,
                        endpoint,
                        {"field": field, "error": error_msg},
                        blocked=True
                    )
                    return False, f"Validation error: {error_msg}"
        
        # Log de requisi√ß√£o v√°lida
        self._log_security_event(
            "valid_request",
            "low",
            source_ip,
            user_agent,
            endpoint,
            {"fields_validated": len(request_data)}
        )
        
        return True, "Valid request"
    
    def _log_security_event(self, event_type: str, severity: str, source_ip: str, 
                          user_agent: str, endpoint: str, details: Dict[str, Any], 
                          blocked: bool = False):
        """Registra evento de seguran√ßa"""
        event = SecurityEvent(
            event_id=secrets.token_hex(16),
            event_type=event_type,
            severity=severity,
            source_ip=source_ip,
            user_agent=user_agent or "unknown",
            endpoint=endpoint,
            payload_hash=hashlib.sha256(json.dumps(details, sort_keys=True).encode()).hexdigest(),
            timestamp=datetime.now(),
            details=details,
            blocked=blocked
        )
        
        self.audit_logger.log_security_event(event)
    
    def get_security_dashboard_data(self) -> Dict[str, Any]:
        """Retorna dados para dashboard de seguran√ßa"""
        # Eventos recentes
        recent_events = self.audit_logger.get_security_events(24)
        
        # Estat√≠sticas
        total_events = len(recent_events)
        blocked_events = len([e for e in recent_events if e['blocked']])
        critical_events = len([e for e in recent_events if e['severity'] == 'critical'])
        
        # Top IPs suspeitos
        ip_counts = defaultdict(int)
        for event in recent_events:
            if event['blocked']:
                ip_counts[event['source_ip']] += 1
        
        top_suspicious_ips = sorted(ip_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        # M√©tricas de performance
        performance_metrics = self.performance_optimizer.get_performance_metrics()
        
        return {
            "security_summary": {
                "total_events_24h": total_events,
                "blocked_events_24h": blocked_events,
                "critical_events_24h": critical_events,
                "blocked_ips_count": len(self.rate_limiter.blocked_ips),
                "suspicious_ips_count": len(self.rate_limiter.suspicious_ips)
            },
            "top_suspicious_ips": top_suspicious_ips,
            "recent_events": recent_events[:50],  # √öltimos 50 eventos
            "performance_metrics": performance_metrics,
            "rate_limiting": {
                "rules": self.rate_limiter.rules,
                "blocked_ips": list(self.rate_limiter.blocked_ips),
                "suspicious_ips": dict(self.rate_limiter.suspicious_ips)
            }
        }
    
    def cleanup_old_data(self, days: int = 30):
        """Limpa dados antigos para otimiza√ß√£o"""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # Limpar eventos de seguran√ßa antigos
        conn = sqlite3.connect(self.audit_logger.db_path)
        cursor = conn.cursor()
        
        cursor.execute("DELETE FROM security_events WHERE timestamp < ?", (cutoff_date,))
        deleted_count = cursor.rowcount
        
        conn.commit()
        conn.close()
        
        logger.info(f"üßπ Limpeza conclu√≠da: {deleted_count} eventos antigos removidos")
        
        return deleted_count
    
    def shutdown(self):
        """Encerra sistema de seguran√ßa"""
        self.audit_logger.stop_processing()
        logger.info("üõ°Ô∏è Sistema de seguran√ßa encerrado")


if __name__ == "__main__":
    # Teste do sistema de seguran√ßa
    security_system = SecurityEnhancementSystem()
    
    try:
        print("üõ°Ô∏è Sistema de seguran√ßa iniciado")
        
        # Simular algumas requisi√ß√µes
        test_requests = [
            {"agent_id": "test_001", "message": "Hello world"},
            {"agent_id": "test_002", "message": "SELECT * FROM users"},  # SQL injection
            {"agent_id": "test_003", "message": "<script>alert('xss')</script>"},  # XSS
            {"agent_id": "valid_agent", "message": "Normal message"}
        ]
        
        for i, request_data in enumerate(test_requests):
            valid, message = security_system.validate_request(
                request_data,
                f"192.168.1.{i+1}",
                "TestAgent/1.0",
                "/api/test"
            )
            print(f"Requisi√ß√£o {i+1}: {'‚úÖ V√°lida' if valid else '‚ùå Bloqueada'} - {message}")
        
        # Aguardar processamento
        time.sleep(2)
        
        # Obter dados do dashboard
        dashboard_data = security_system.get_security_dashboard_data()
        print(f"\nüìä DASHBOARD DE SEGURAN√áA:")
        print(f"Total de eventos: {dashboard_data['security_summary']['total_events_24h']}")
        print(f"Eventos bloqueados: {dashboard_data['security_summary']['blocked_events_24h']}")
        print(f"Cache hit rate: {dashboard_data['performance_metrics']['cache']['hit_rate']:.2%}")
        
    except KeyboardInterrupt:
        print("\nüõë Interrompido pelo usu√°rio")
    finally:
        security_system.shutdown()

